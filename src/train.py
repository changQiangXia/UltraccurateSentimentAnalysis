"""
è®­ç»ƒè„šæœ¬
æ”¯æŒ R-Dropã€æ··åˆç²¾åº¦è®­ç»ƒ (FP16)ã€æ–­ç‚¹ç»­è®­
é’ˆå¯¹ 4GB æ˜¾å­˜ä¼˜åŒ–
"""

import os
import sys
import json
import yaml
import logging
import argparse
from pathlib import Path
from typing import Dict, List, Optional

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score, classification_report

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.model import SentimentAnalyzer, load_model_and_tokenizer
from transformers import AutoTokenizer, get_linear_schedule_with_warmup


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SentimentDataset(Dataset):
    """æƒ…æ„Ÿåˆ†ææ•°æ®é›†"""
    
    def __init__(self, data_path: str, tokenizer, max_length: int = 128):
        """
        Args:
            data_path: jsonl æ–‡ä»¶è·¯å¾„
            tokenizer: åˆ†è¯å™¨
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
        """
        self.tokenizer = tokenizer
        self.max_length = max_length
        
        with open(data_path, 'r', encoding='utf-8') as f:
            self.data = [json.loads(line) for line in f]
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        text = item['text']
        labels = item['labels']
        
        # ç¼–ç 
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'token_type_ids': encoding.get('token_type_ids', torch.zeros_like(encoding['input_ids'])).squeeze(0),
            'labels': torch.tensor(labels, dtype=torch.long)
        }


class Trainer:
    """è®­ç»ƒå™¨ï¼ˆæ”¯æŒæ–­ç‚¹ç»­è®­ï¼‰"""
    
    def __init__(self, config: Dict, resume: bool = False):
        """
        Args:
            config: é…ç½®å­—å…¸
            resume: æ˜¯å¦ä» checkpoint æ¢å¤
        """
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # è®­ç»ƒçŠ¶æ€
        self.global_step = 0
        self.current_epoch = 0
        self.best_metric = float('-inf')
        
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
        logger.info(f"åŠ è½½æ¨¡å‹: {config['model']['name']}")
        
        # è·å–ç±»åˆ«åŠ æƒé…ç½®
        use_weighted_loss = config['model'].get('use_weighted_loss', True)
        class_weights = config['model'].get('class_weights', None)
        
        if use_weighted_loss and class_weights:
            logger.info(f"ä½¿ç”¨ç±»åˆ«åŠ æƒ Loss: {class_weights}")
        
        self.model, self.tokenizer = load_model_and_tokenizer(
            model_name=config['model']['name'],
            num_labels=config['model']['num_labels'],
            dropout=config['model']['hidden_dropout_prob'],
            use_rdrop=config['rdrop']['enabled'],
            rdrop_alpha=config['rdrop']['alpha'],
            use_weighted_loss=use_weighted_loss,
            class_weights=class_weights
        )
        self.model.to(self.device)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config['training']['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ··åˆç²¾åº¦è®­ç»ƒ
        self.use_fp16 = config['training'].get('fp16', False) and torch.cuda.is_available()
        if self.use_fp16:
            try:
                from torch.amp import GradScaler
                self.scaler = GradScaler('cuda')
            except ImportError:
                from torch.cuda.amp import GradScaler
                self.scaler = GradScaler()
            logger.info("å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (FP16)")
        
        # ä¼˜åŒ–å™¨
        self.optimizer = self._create_optimizer()
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆå°†åœ¨ train ä¸­åˆå§‹åŒ–ï¼‰
        self.scheduler = None
        
        # æ–­ç‚¹ç»­è®­
        if resume:
            self.resume_from_checkpoint()
    
    def _create_optimizer(self):
        """åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆæ”¯æŒå±‚ wise å­¦ä¹ ç‡è¡°å‡ï¼‰"""
        no_decay = ['bias', 'LayerNorm.weight']
        
        # å±‚ wise å­¦ä¹ ç‡è¡°å‡é…ç½®
        layer_decay = self.config['training'].get('layer_wise_lr_decay', 0.95)
        base_lr = self.config['training']['learning_rate']
        
        # åˆ†ç»„å‚æ•°
        optimizer_grouped_parameters = []
        
        # BERT å±‚ï¼ˆä»åº•å±‚åˆ°é¡¶å±‚é€’å‡å­¦ä¹ ç‡ï¼‰
        num_layers = self.model.bert.config.num_hidden_layers
        
        for layer_num in range(num_layers):
            # å±‚å·è¶Šå¤§ï¼ˆè¶Šé è¿‘è¾“å‡ºï¼‰ï¼Œå­¦ä¹ ç‡è¶Šé«˜
            layer_lr = base_lr * (layer_decay ** (num_layers - layer_num - 1))
            
            # è¯¥å±‚çš„å‚æ•°
            layer_params_decay = []
            layer_params_no_decay = []
            
            for n, p in self.model.named_parameters():
                if f'encoder.layer.{layer_num}.' in n:
                    if any(nd in n for nd in no_decay):
                        layer_params_no_decay.append(p)
                    else:
                        layer_params_decay.append(p)
            
            if layer_params_decay:
                optimizer_grouped_parameters.append({
                    'params': layer_params_decay,
                    'lr': layer_lr,
                    'weight_decay': self.config['training']['weight_decay']
                })
            if layer_params_no_decay:
                optimizer_grouped_parameters.append({
                    'params': layer_params_no_decay,
                    'lr': layer_lr,
                    'weight_decay': 0.0
                })
        
        # è¾“å‡ºå±‚ï¼ˆåˆ†ç±»å¤´ï¼‰ä½¿ç”¨æœ€å¤§å­¦ä¹ ç‡
        classifier_params_decay = []
        classifier_params_no_decay = []
        
        for n, p in self.model.named_parameters():
            if 'classifiers' in n or 'classifier' in n:
                if any(nd in n for nd in no_decay):
                    classifier_params_no_decay.append(p)
                else:
                    classifier_params_decay.append(p)
        
        if classifier_params_decay:
            optimizer_grouped_parameters.append({
                'params': classifier_params_decay,
                'lr': base_lr,  # æœ€é«˜å­¦ä¹ ç‡
                'weight_decay': self.config['training']['weight_decay']
            })
        if classifier_params_no_decay:
            optimizer_grouped_parameters.append({
                'params': classifier_params_no_decay,
                'lr': base_lr,
                'weight_decay': 0.0
            })
        
        # ä½¿ç”¨ AdamW
        from torch.optim import AdamW
        optimizer = AdamW(optimizer_grouped_parameters, lr=base_lr)
        
        # æ‰“å°å„å±‚å­¦ä¹ ç‡
        print("\nå±‚ wise å­¦ä¹ ç‡é…ç½®:")
        for i, group in enumerate(optimizer_grouped_parameters[:6]):  # åªæ‰“å°å‰6ç»„
            print(f"  Group {i}: lr={group['lr']:.2e}, decay={group['weight_decay']}")
        
        return optimizer
    
    def _create_dataloader(self, data_path: str, shuffle: bool = True) -> DataLoader:
        """åˆ›å»º DataLoader"""
        dataset = SentimentDataset(
            data_path=data_path,
            tokenizer=self.tokenizer,
            max_length=self.config['model']['max_length']
        )
        
        return DataLoader(
            dataset,
            batch_size=self.config['training']['per_device_train_batch_size'],
            shuffle=shuffle,
            num_workers=self.config['training'].get('dataloader_num_workers', 0),
            pin_memory=self.config['training'].get('dataloader_pin_memory', False)
        )
    
    def resume_from_checkpoint(self):
        """ä» checkpoint æ¢å¤è®­ç»ƒçŠ¶æ€"""
        checkpoint_dir = self.output_dir / 'checkpoint-latest'
        
        if not checkpoint_dir.exists():
            logger.warning(f"æ²¡æœ‰æ‰¾åˆ° checkpoint: {checkpoint_dir}")
            logger.warning("å°†ä»å¤´å¼€å§‹è®­ç»ƒ")
            return
        
        logger.info(f"ä» checkpoint æ¢å¤: {checkpoint_dir}")
        
        # åŠ è½½æ¨¡å‹æƒé‡
        model_path = checkpoint_dir / 'pytorch_model.bin'
        if model_path.exists():
            state_dict = torch.load(model_path, map_location=self.device)
            self.model.load_state_dict(state_dict)
            logger.info("æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
        
        # åŠ è½½è®­ç»ƒçŠ¶æ€
        trainer_state_path = checkpoint_dir / 'trainer_state.json'
        if trainer_state_path.exists():
            with open(trainer_state_path, 'r', encoding='utf-8') as f:
                state = json.load(f)
            
            self.global_step = state.get('global_step', 0)
            self.current_epoch = state.get('current_epoch', 0)
            self.best_metric = state.get('best_metric', float('-inf'))
            
            logger.info(f"æ¢å¤è®­ç»ƒçŠ¶æ€: epoch={self.current_epoch}, step={self.global_step}, best_metric={self.best_metric:.4f}")
        
        # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€
        optimizer_path = checkpoint_dir / 'optimizer.pt'
        if optimizer_path.exists():
            optimizer_state = torch.load(optimizer_path, map_location=self.device)
            self.optimizer.load_state_dict(optimizer_state)
            logger.info("ä¼˜åŒ–å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")
        
        # åŠ è½½ scheduler çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        scheduler_path = checkpoint_dir / 'scheduler.pt'
        if scheduler_path.exists():
            self.scheduler_state = torch.load(scheduler_path)
            logger.info("å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")
        else:
            self.scheduler_state = None
        
        logger.info("æ–­ç‚¹ç»­è®­å‡†å¤‡å®Œæˆï¼")
    
    def train(self, train_path: str, eval_path: str):
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            train_path: è®­ç»ƒé›†è·¯å¾„
            eval_path: éªŒè¯é›†è·¯å¾„
        """
        train_loader = self._create_dataloader(train_path, shuffle=True)
        eval_loader = self._create_dataloader(eval_path, shuffle=False)
        
        # è®¡ç®—æ€»è®­ç»ƒæ­¥æ•°
        epochs = self.config['training']['num_train_epochs']
        steps_per_epoch = len(train_loader)
        total_steps = steps_per_epoch * epochs
        warmup_steps = int(total_steps * self.config['training']['warmup_ratio'])
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = get_linear_schedule_with_warmup(
            self.optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=total_steps
        )
        
        # å¦‚æœä» checkpoint æ¢å¤ï¼ŒåŠ è½½ scheduler çŠ¶æ€
        if hasattr(self, 'scheduler_state') and self.scheduler_state is not None:
            self.scheduler.load_state_dict(self.scheduler_state)
            logger.info("å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€å·²æ¢å¤")
        
        logger.info(f"æ€»è®­ç»ƒæ­¥æ•°: {total_steps}, Warmup æ­¥æ•°: {warmup_steps}")
        logger.info(f"æ¯ epoch æ­¥æ•°: {steps_per_epoch}")
        
        # å¦‚æœä» checkpoint æ¢å¤ï¼Œè·³è¿‡å·²è®­ç»ƒçš„ epoch
        start_epoch = self.current_epoch
        if start_epoch > 0:
            logger.info(f"ä» epoch {start_epoch + 1} ç»§ç»­è®­ç»ƒï¼ˆå·²è·³è¿‡å‰ {start_epoch} ä¸ª epochï¼‰")
        
        # Early Stopping è®¾ç½®
        patience = self.config['training'].get('early_stopping_patience', 5)
        no_improve_count = 0
        metric_for_best = self.config['training']['metric_for_best_model']
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(start_epoch, epochs):
            self.current_epoch = epoch
            logger.info(f"\n===== Epoch {epoch + 1}/{epochs} =====")
            
            # è®­ç»ƒé˜¶æ®µ
            train_loss = self._train_epoch(train_loader, steps_per_epoch)
            logger.info(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}")
            
            # éªŒè¯é˜¶æ®µ
            eval_metrics = self._eval_epoch(eval_loader)
            logger.info(f"éªŒè¯æŒ‡æ ‡: {eval_metrics}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            current_metric = eval_metrics.get(metric_for_best, 0)
            
            if current_metric > self.best_metric:
                improvement = current_metric - self.best_metric
                self.best_metric = current_metric
                self._save_model('best_model')
                logger.info(f"ğŸ‰ æ–°æœ€ä½³æ¨¡å‹ï¼{metric_for_best}: {current_metric:.4f} (+{improvement:.4f})")
                no_improve_count = 0  # é‡ç½®è®¡æ•°å™¨
            else:
                no_improve_count += 1
                logger.info(f"æœªæå‡ ({no_improve_count}/{patience})")
            
            # ä¿å­˜ checkpointï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰
            self._save_checkpoint('checkpoint-latest')
            
            # å®šæœŸä¿å­˜å†å² checkpoint
            if (epoch + 1) % 1 == 0:
                self._save_checkpoint(f'checkpoint-epoch-{epoch + 1}')
            
            # Early Stopping æ£€æŸ¥
            if no_improve_count >= patience:
                logger.info(f"\nâ¹ï¸ Early Stopping: {patience} ä¸ª epoch æ— æå‡ï¼Œåœæ­¢è®­ç»ƒ")
                break
            
            # æ¸…ç†æ˜¾å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        logger.info("\nè®­ç»ƒå®Œæˆï¼")
        logger.info(f"æœ€ä½³ {metric_for_best}: {self.best_metric:.4f}")
        logger.info(f"æ€»è®­ç»ƒæ­¥æ•°: {self.global_step}")
    
    def _train_epoch(self, dataloader: DataLoader, steps_per_epoch: int) -> float:
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        total_loss = 0.0
        
        progress_bar = tqdm(dataloader, desc=f"Epoch {self.current_epoch + 1}")
        
        for batch in progress_bar:
            # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            token_type_ids = batch['token_type_ids'].to(self.device)
            labels = batch['labels'].to(self.device)
            
            # æ¸…é›¶æ¢¯åº¦
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            if self.use_fp16:
                try:
                    from torch.amp import autocast
                    with autocast('cuda'):
                        outputs = self.model.rdrop_forward(
                            input_ids=input_ids,
                            attention_mask=attention_mask,
                            token_type_ids=token_type_ids,
                            labels=labels
                        )
                        loss = outputs['loss']
                except ImportError:
                    from torch.cuda.amp import autocast
                    with autocast():
                        outputs = self.model.rdrop_forward(
                            input_ids=input_ids,
                            attention_mask=attention_mask,
                            token_type_ids=token_type_ids,
                            labels=labels
                        )
                        loss = outputs['loss']
                
                # åå‘ä¼ æ’­ï¼ˆæ··åˆç²¾åº¦ï¼‰
                self.scaler.scale(loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                outputs = self.model.rdrop_forward(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    token_type_ids=token_type_ids,
                    labels=labels
                )
                loss = outputs['loss']
                
                # åå‘ä¼ æ’­
                loss.backward()
                self.optimizer.step()
            
            # æ›´æ–°å­¦ä¹ ç‡
            self.scheduler.step()
            
            # è®°å½•æŸå¤±
            total_loss += loss.item()
            self.global_step += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{self.scheduler.get_last_lr()[0]:.2e}',
                'step': self.global_step
            })
            
            # å®šæœŸè®°å½•
            if self.global_step % self.config['training']['logging_steps'] == 0:
                logger.info(f"Step {self.global_step}: loss={loss.item():.4f}")
        
        return total_loss / len(dataloader)
    
    def _eval_epoch(self, dataloader: DataLoader) -> Dict[str, float]:
        """éªŒè¯ä¸€ä¸ª epoch"""
        self.model.eval()
        
        all_preds = []
        all_labels = []
        total_loss = 0.0
        
        with torch.no_grad():
            for batch in tqdm(dataloader, desc="Evaluating"):
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                token_type_ids = batch['token_type_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                # å‰å‘ä¼ æ’­
                outputs = self.model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    token_type_ids=token_type_ids,
                    labels=labels
                )
                
                loss = outputs['loss']
                logits = outputs['logits']
                
                total_loss += loss.item()
                
                # é¢„æµ‹
                preds = torch.argmax(logits, dim=-1).cpu().numpy()
                labels_np = labels.cpu().numpy()
                
                all_preds.append(preds)
                all_labels.append(labels_np)
        
        # åˆå¹¶æ‰€æœ‰é¢„æµ‹
        all_preds = np.concatenate(all_preds, axis=0)
        all_labels = np.concatenate(all_labels, axis=0)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = self._compute_metrics(all_preds, all_labels)
        metrics['loss'] = total_loss / len(dataloader)
        
        return metrics
    
    def _compute_metrics(self, preds: np.ndarray, labels: np.ndarray) -> Dict[str, float]:
        """
        è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        
        Args:
            preds: é¢„æµ‹ç»“æœ [num_samples, num_labels]
            labels: çœŸå®æ ‡ç­¾ [num_samples, num_labels]
            
        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        # æ¯ä¸ªç»´åº¦çš„å‡†ç¡®ç‡
        dim_accuracies = []
        for i in range(preds.shape[1]):
            acc = accuracy_score(labels[:, i], preds[:, i])
            dim_accuracies.append(acc)
        
        # æ•´ä½“å‡†ç¡®ç‡ï¼ˆæ‰€æœ‰ç»´åº¦éƒ½æ­£ç¡®ï¼‰
        overall_acc = np.all(preds == labels, axis=1).mean()
        
        # å¹³å‡ F1ï¼ˆmacroï¼‰
        f1_macros = []
        for i in range(preds.shape[1]):
            f1 = f1_score(labels[:, i], preds[:, i], average='macro', zero_division=0)
            f1_macros.append(f1)
        
        metrics = {
            'accuracy': overall_acc,
            'avg_dim_accuracy': np.mean(dim_accuracies),
            'f1_macro': np.mean(f1_macros),
            'avg_dim_f1': np.mean(f1_macros)
        }
        
        return metrics
    
    def _save_checkpoint(self, name: str):
        """ä¿å­˜å®Œæ•´ checkpointï¼ˆç”¨äºæ–­ç‚¹ç»­è®­ï¼‰"""
        save_dir = self.output_dir / name
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹æƒé‡
        torch.save(self.model.state_dict(), save_dir / 'pytorch_model.bin')
        
        # ä¿å­˜è®­ç»ƒçŠ¶æ€
        trainer_state = {
            'global_step': self.global_step,
            'current_epoch': self.current_epoch,
            'best_metric': self.best_metric,
            'config': self.config
        }
        with open(save_dir / 'trainer_state.json', 'w', encoding='utf-8') as f:
            json.dump(trainer_state, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€
        torch.save(self.optimizer.state_dict(), save_dir / 'optimizer.pt')
        
        # ä¿å­˜ scheduler çŠ¶æ€
        if self.scheduler is not None:
            torch.save(self.scheduler.state_dict(), save_dir / 'scheduler.pt')
        
        # ä¿å­˜åˆ†è¯å™¨
        self.tokenizer.save_pretrained(save_dir)
        
        logger.info(f"Checkpoint å·²ä¿å­˜: {save_dir} (epoch={self.current_epoch + 1}, step={self.global_step})")
    
    def _save_model(self, name: str):
        """ä¿å­˜æ¨¡å‹ï¼ˆç®€æ´ç‰ˆæœ¬ï¼Œç”¨äºéƒ¨ç½²ï¼‰"""
        save_dir = self.output_dir / name
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹æƒé‡
        torch.save(self.model.state_dict(), save_dir / 'pytorch_model.bin')
        
        # ä¿å­˜é…ç½®
        config = {
            'model_name': self.config['model']['name'],
            'num_labels': self.config['model']['num_labels'],
            'hidden_dropout_prob': self.config['model']['hidden_dropout_prob']
        }
        with open(save_dir / 'config.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜åˆ†è¯å™¨
        self.tokenizer.save_pretrained(save_dir)
        
        logger.info(f"æ¨¡å‹å·²ä¿å­˜: {save_dir}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è®­ç»ƒæƒ…æ„Ÿåˆ†ææ¨¡å‹')
    parser.add_argument('--config', type=str, default='configs/hyperparams.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--train_file', type=str, default=None,
                        help='è®­ç»ƒæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--eval_file', type=str, default=None,
                        help='éªŒè¯æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', action='store_true',
                        help='ä» checkpoint æ–­ç‚¹ç»­è®­')
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    if args.train_file:
        config['data']['train_file'] = args.train_file
    if args.eval_file:
        config['data']['eval_file'] = args.eval_file
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(config, resume=args.resume)
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(
        train_path=config['data']['train_file'],
        eval_path=config['data']['eval_file']
    )


if __name__ == "__main__":
    main()
